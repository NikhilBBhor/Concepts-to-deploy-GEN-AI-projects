-- create an vertual enviornment --> python -m venv venv

-- activate vertual enviornment --> Mac/Linux -->> source venv/bin/activate
                                 Windows -->> venv\Scripts\activate

-- install tiktoken >> developed by OpenAI (OpenAI uses it for tokenization)

-- do --> pip freeze > requirements.txt  # Saves installed libraries with versions

-- Vocab Size: Total number of different words (unique tokens) on which model is trained
               (total no of words in the dictionary of the model)

