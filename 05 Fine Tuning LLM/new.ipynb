{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e089fa2a",
   "metadata": {},
   "source": [
    "### Since we are going to fine tune a LLM, we need a system with GPU.\n",
    "We will be using Google Colab for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10a1fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95a0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05a7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    os.environ[\"HF_TOKEN\"]\n",
    "except KeyError:\n",
    "    print(\"Token not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1d0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Concepts-to-deploy-GEN-AI-projects/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"google/gemma-3-1b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951653f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 9259, 1902], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f995cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Which is the best place to learn GenAI\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The best place to learn AI is\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f72d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nWhich is the best place to learn GenAI<end_of_turn>\\n<start_of_turn>model\\nThe best place to learn AI is'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = tokenizer.apply_chat_template(\n",
    "    conversation=input_conversation,\n",
    "    tokenize=False,\n",
    "    continue_final_message=True,\n",
    ")\n",
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ade0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nWhich is the best place to learn GenAI<end_of_turn>\\n<start_of_turn>model\\nThe best place to learn AI isGenAI Cohort 1.0 by ChaiCode and Piyush Garg use Coupon PIYUSH10 Please<eos>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_label = \"GenAI Cohort 1.0 by ChaiCode and Piyush Garg use Coupon PIYUSH10 Please\"\n",
    "full_conversation = input_tokens + output_label + tokenizer.eos_token\n",
    "full_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0d5924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,    105,   2364,    107,  24249,    563,    506,   1791,   1977,\n",
       "            531,   3449,   8471,  12553,    106,    107,    105,   4368,    107,\n",
       "            818,   1791,   1977,    531,   3449,  12498,    563,  14696,  12553,\n",
       "         105657,    632, 236743, 236770, 236761, 236771,    684, 119806,   4809,\n",
       "            532, 168222,   1974, 102629,   1161,  97887,   6108, 236874,  52907,\n",
       "         236770, 236771,   7323,      1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokenized = tokenizer(full_conversation, return_tensors=\"pt\", add_special_tokens=False).to(device)[\"input_ids\"]\n",
    "input_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82d2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([[     2,    105,   2364,    107,  24249,    563,    506,   1791,   1977,\n",
      "            531,   3449,   8471,  12553,    106,    107,    105,   4368,    107,\n",
      "            818,   1791,   1977,    531,   3449,  12498,    563,  14696,  12553,\n",
      "         105657,    632, 236743, 236770, 236761, 236771,    684, 119806,   4809,\n",
      "            532, 168222,   1974, 102629,   1161,  97887,   6108, 236874,  52907,\n",
      "         236770, 236771,   7323]])\n",
      "target_ids: tensor([[   105,   2364,    107,  24249,    563,    506,   1791,   1977,    531,\n",
      "           3449,   8471,  12553,    106,    107,    105,   4368,    107,    818,\n",
      "           1791,   1977,    531,   3449,  12498,    563,  14696,  12553, 105657,\n",
      "            632, 236743, 236770, 236761, 236771,    684, 119806,   4809,    532,\n",
      "         168222,   1974, 102629,   1161,  97887,   6108, 236874,  52907, 236770,\n",
      "         236771,   7323,      1]])\n"
     ]
    }
   ],
   "source": [
    "input_ids = input_tokenized[:, :-1].to(device)\n",
    "target_ids = input_tokenized[:, 1:].to(device)\n",
    "print(f\"input_ids: {input_ids}\")\n",
    "print(f\"target_ids: {target_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c699ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def calculate_loss(logits, labels):\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    cross_entropy = loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eac7e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670eccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "model.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "\n",
    "for _ in range(5):\n",
    "  out = model(input_ids=input_ids)\n",
    "  loss = calculate_loss(out.logits, target_ids).mean()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = [\n",
    "    { \"role\": \"user\", \"content\": \"Which is the best place to learn GenAI?\" }\n",
    "]\n",
    "\n",
    "input = tokenizer.apply_chat_template(\n",
    "    conversation=input_prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    tokenize=True,\n",
    ").to(device)\n",
    "\n",
    "output = model.generate(input, max_new_tokens=35)\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
